{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance evaluation for summary dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE scores...\n",
      "Calculating BERTScore (this may take a while for large datasets)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 74.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 656157.05 seconds, 0.00 sentences/sec\n",
      "\n",
      "=== Summary Evaluation Results ===\n",
      "ROUGE-1: 0.1734\n",
      "ROUGE-2: 0.0650\n",
      "BERTScore F1: 0.8521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.17338318792411023,\n",
       " 'rouge2': 0.0649617871840094,\n",
       " 'rougeL': 0.14125467386788534,\n",
       " 'rougeLsum': 0.14125467386788534,\n",
       " 'bertscore_precision': 0.859481950600942,\n",
       " 'bertscore_recall': 0.8452408909797668,\n",
       " 'bertscore_f1': 0.8520694375038147,\n",
       " 'bertscore_hash': 'roberta-large_L17_no-idf_version=0.3.12(hug_trans=4.49.0)'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def measure_performance_summary_inference(true_labels, pred_labels, wandb_run=None):\n",
    "    \"\"\"\n",
    "    Evaluate summarization performance between true and predicted summaries.\n",
    "    \n",
    "    Args:\n",
    "        true_labels (List[str]): List of reference/ground truth summaries\n",
    "        pred_labels (List[str]): List of model-generated summaries to evaluate\n",
    "        wandb_run: Optional Weights & Biases run object for logging metrics\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing the evaluation metrics\n",
    "    \"\"\"\n",
    "    # Initialize metrics dictionary\n",
    "    metrics = {}\n",
    "    \n",
    "    # Import necessary libraries for evaluation\n",
    "    rouge = evaluate.load('rouge')\n",
    "    bertscore = evaluate.load('bertscore')\n",
    "    \n",
    "    # Format references for the evaluate library format\n",
    "    # For each prediction, we have exactly one reference\n",
    "    references = [[label] for label in true_labels]\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    print(\"Calculating ROUGE scores...\")\n",
    "    try:\n",
    "        rouge_results = rouge.compute(\n",
    "            predictions=pred_labels,\n",
    "            references=references,\n",
    "            use_stemmer=True\n",
    "        )\n",
    "        \n",
    "        # Add ROUGE metrics to the metrics dictionary\n",
    "        for metric_name, value in rouge_results.items():\n",
    "            metrics[metric_name] = value\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating ROUGE scores: {e}\")\n",
    "    \n",
    "    # Calculate BERTScore\n",
    "    print(\"Calculating BERTScore (this may take a while for large datasets)...\")\n",
    "    try:\n",
    "        # For BERTScore, we need to provide the single reference for each prediction\n",
    "        # Since our references are in the format [[ref1], [ref2], ...], we extract the first element\n",
    "        bertscore_results = bertscore.compute(\n",
    "            predictions=pred_labels,\n",
    "            references=[ref[0] for ref in references],  # Extract single reference for each prediction\n",
    "            lang=\"en\",\n",
    "            model_type=None,  # Uses the suggested model for the target language\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Add BERTScore metrics\n",
    "        metrics['bertscore_precision'] = np.mean(bertscore_results['precision'])\n",
    "        metrics['bertscore_recall'] = np.mean(bertscore_results['recall'])\n",
    "        metrics['bertscore_f1'] = np.mean(bertscore_results['f1'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating BERTScore: {e}\")\n",
    "        metrics['bertscore_precision'] = None\n",
    "        metrics['bertscore_recall'] = None\n",
    "        metrics['bertscore_f1'] = None\n",
    "        metrics['bertscore_hash'] = None\n",
    "    \n",
    "    # Print summary of results\n",
    "    print(\"\\n=== Summary Evaluation Results ===\")\n",
    "    if 'rouge1' in metrics:\n",
    "        print(f\"ROUGE-1: {metrics['rouge1']:.4f}\")\n",
    "    if 'rouge2' in metrics:\n",
    "        print(f\"ROUGE-2: {metrics['rouge2']:.4f}\")\n",
    "    if 'bertscore_f1' in metrics and metrics['bertscore_f1'] is not None:\n",
    "        print(f\"BERTScore F1: {metrics['bertscore_f1']:.4f}\")\n",
    "    \n",
    "    # Log metrics to wandb if provided\n",
    "    if wandb_run:\n",
    "        wandb_run.log({\n",
    "            \"rouge1\": metrics.get('rouge1', None),\n",
    "            \"rouge2\": metrics.get('rouge2', None),\n",
    "            \"bertscore_f1\": metrics.get('bertscore_f1', None)\n",
    "        })\n",
    "        \n",
    "        # Create a summary table for wandb\n",
    "        valid_metrics = {k: v for k, v in metrics.items() if v is not None}\n",
    "        metrics_table = pd.DataFrame({\n",
    "            'Metric': list(valid_metrics.keys()),\n",
    "            'Value': list(valid_metrics.values())\n",
    "        })\n",
    "        \n",
    "        wandb_run.log({\"metrics_summary\": wandb.Table(dataframe=metrics_table)})\n",
    "\n",
    "example_true_labels = [\n",
    "    \"q1 revenue rose 11.1 percent to $481.1 million. q1 non-gaap earnings per share $1.24. sees fy revenue $1.725 billion to $1.775 billion.\",\n",
    "    \"q1 adjusted earnings per share $3.34. q1 sales $3.3 billion versus refinitiv ibes estimate of $3.28 billion. q1 same store sales rose 24.7 percent.\",\n",
    "    \"advance auto parts q2 adjusted earnings per share $3.40. q2 adjusted earnings per share $3.40. q2 sales $2.6 billion versus refinitiv ibes estimate of $2.64 billion. q2 same store sales rose 5.8 percent.increased full year 2021 guidance.\",\n",
    "]\n",
    "\n",
    "example_pred_labels = [\n",
    "    \"compname reports q3 adjusted earnings per share of $3.21. q3 adjusted earnings per share $3.21. q3 sales rose 3.1 percent to $2.6 billion. q3 same store sales rose 3.1 percent. sees 2021 capital expenditures of minimum $275 million. sees fy 2021 comparable store sales growth of 9.5% to 10%.\",\n",
    "    \"withdrew its full year 2020 guidance that was previously issued on october 29, 2019.\",\n",
    "    \"american assets trust q2 ffo per share $0.48. q2 ffo per share $0.48.\"\n",
    "]\n",
    "\n",
    "measure_performance_summary_inference(true_labels=example_true_labels, pred_labels=example_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed issue with completion formatted as dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9129/9129 [00:00<00:00, 25155.90 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9129/9129 [00:00<00:00, 340480.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified dataset saved to distillation-data/gold/llama3.3:70b-instruct-q4_K_M/earnest-grass-131-mod\n",
      "Original completion type: <class 'dict'>\n",
      "Modified completion type: <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "import json\n",
    "\n",
    "def convert_completion_to_string(dataset_path, output_path):\n",
    "    \"\"\"\n",
    "    Load a dataset, convert 'completion' field from dict to string, and save the modified dataset.\n",
    "    \n",
    "    Args:\n",
    "        dataset_path: Path to the original dataset\n",
    "        output_path: Path where the modified dataset will be saved\n",
    "    \"\"\"\n",
    "    # Load the dataset\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    \n",
    "    # Function to convert completion field from dict to string\n",
    "    def convert_completion(example):\n",
    "        if isinstance(example['completion'], dict):\n",
    "            # Convert the dictionary to a properly formatted JSON string\n",
    "            example['completion'] = json.dumps(example['completion'], indent=None, separators=(',', ':'))\n",
    "        return example\n",
    "    \n",
    "    # Apply the conversion function to each element\n",
    "    modified_dataset = dataset.map(convert_completion)\n",
    "    \n",
    "    # Save the modified dataset\n",
    "    modified_dataset.save_to_disk(output_path)\n",
    "    \n",
    "    print(f\"Modified dataset saved to {output_path}\")\n",
    "    print(f\"Original completion type: {type(dataset[0]['completion'])}\")\n",
    "    print(f\"Modified completion type: {type(modified_dataset[0]['completion'])}\")\n",
    "    \n",
    "    return modified_dataset\n",
    "\n",
    "# Execute the function\n",
    "original_path = \"distillation-data/gold/llama3.3:70b-instruct-q4_K_M/earnest-grass-131\"\n",
    "output_path = \"distillation-data/gold/llama3.3:70b-instruct-q4_K_M/earnest-grass-131-mod\"\n",
    "modified_dataset = convert_completion_to_string(original_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test ECTSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_manager import SummaryManager\n",
    "\n",
    "prompts, true_labels, pred_labels = SummaryManager.load_data(\"summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Majority "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'price_or_not': 1,\n",
       " 'price_up': 0,\n",
       " 'price_const_stable': 0,\n",
       " 'price_down': 1,\n",
       " 'past_price_info': 1,\n",
       " 'future_price_info': 1,\n",
       " 'past_gen_info': 0,\n",
       " 'future_gen_info': 0,\n",
       " 'asset_comparison': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models.query_utils import find_majority_dict\n",
    "\n",
    "example_1 = {\n",
    "    \"price_or_not\": 1,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 1,\n",
    "    \"price_down\": 0,\n",
    "    \"past_price_info\": 0,\n",
    "    \"future_price_info\": 1,\n",
    "    \"past_gen_info\": 0,\n",
    "    \"future_gen_info\": 0,\n",
    "    \"asset_comparison\": 0\n",
    "}\n",
    "\n",
    "example_2 = {\n",
    "    \"price_or_not\": 0,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 0,\n",
    "    \"price_down\": 1,\n",
    "    \"past_price_info\": 1,\n",
    "    \"future_price_info\": 0,\n",
    "    \"past_gen_info\": 1,\n",
    "    \"future_gen_info\": 0,\n",
    "    \"asset_comparison\": 1\n",
    "}\n",
    "\n",
    "example_3 = {\n",
    "    \"price_or_not\": 1,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 0,\n",
    "    \"price_down\": 1,\n",
    "    \"past_price_info\": 1,\n",
    "    \"future_price_info\": 1,\n",
    "    \"past_gen_info\": 0,\n",
    "    \"future_gen_info\": 0,\n",
    "    \"asset_comparison\": 1\n",
    "}\n",
    "\n",
    "examples = [example_1, example_2, example_3]\n",
    "\n",
    "find_majority_dict(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test performance evaluation for gold dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Overall Metrics ===\n",
      "Accuracy: 0.7778\n",
      "Balanced Accuracy: 0.7500\n",
      "F1 Micro: 0.7778\n",
      "Total samples: 27\n",
      "\n",
      "=== Per-Category Metrics ===\n",
      "          Category  Accuracy  Balanced Acc  F1 Micro  Samples\n",
      "      price_or_not       1.0           1.0       1.0        3\n",
      "          price_up       1.0           1.0       1.0        3\n",
      "price_const_stable       0.0           0.0       0.0        3\n",
      "        price_down       1.0           1.0       1.0        3\n",
      "   past_price_info       0.0           0.0       0.0        3\n",
      " future_price_info       1.0           1.0       1.0        3\n",
      "     past_gen_info       1.0           1.0       1.0        3\n",
      "   future_gen_info       1.0           1.0       1.0        3\n",
      "  asset_comparison       1.0           1.0       1.0        3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import wandb\n",
    "\n",
    "def evaluate_multilabel_performance(true_labels: List[Dict[str, int]], pred_labels: List[Dict[str, int]], wandb_run = None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate multi-label classification performance.\n",
    "    \n",
    "    Args:\n",
    "        true_labels: List of dictionaries containing true labels\n",
    "        pred_labels: List of dictionaries containing predicted labels\n",
    "        wandb_run: Optional Weights & Biases run object for logging\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing performance metrics\n",
    "    \"\"\"\n",
    "    # Determine categories if not provided\n",
    "    categories = list(true_labels[0].keys())\n",
    "    \n",
    "    # Initialize metric trackers\n",
    "    metrics_per_category = {}\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    \n",
    "    # Evaluate each category separately\n",
    "    for category in categories:\n",
    "        category_true = []\n",
    "        category_pred = []\n",
    "        \n",
    "        for true_dict, pred_dict in zip(true_labels, pred_labels):\n",
    "            # Skip if category missing in either dictionary\n",
    "            if category not in true_dict or category not in pred_dict:\n",
    "                continue\n",
    "                \n",
    "            true_val = true_dict[category]\n",
    "            \n",
    "            # Handle missing category in pred_dict by treating as incorrect\n",
    "            if category not in pred_dict:\n",
    "                # Force an incorrect prediction\n",
    "                pred_val = 1 - true_val if true_val in (0, 1) else 0\n",
    "            else:\n",
    "                pred_val = pred_dict[category]\n",
    "                \n",
    "                # IMPORTANT CHANGE: Penalize missing predictions (-1) \n",
    "                # by replacing with a value guaranteed to be incorrect\n",
    "                if pred_val == -1:\n",
    "                    # Convert to opposite of true value to ensure it's wrong\n",
    "                    pred_val = 1 - true_val if true_val in (0, 1) else 0\n",
    "\n",
    "            category_true.append(true_val)\n",
    "            category_pred.append(pred_val)\n",
    "            \n",
    "            # Add to overall evaluation\n",
    "            all_true.append(true_val)\n",
    "            all_pred.append(pred_val)\n",
    "        \n",
    "        # Calculate metrics for this category\n",
    "        if category_true and category_pred:\n",
    "            try:\n",
    "                accuracy = accuracy_score(category_true, category_pred)\n",
    "                # Only calculate balanced_accuracy if there are at least two classes\n",
    "                unique_classes = len(set(category_true))\n",
    "                if unique_classes > 1:\n",
    "                    balanced_acc = balanced_accuracy_score(category_true, category_pred)\n",
    "                else:\n",
    "                    balanced_acc = accuracy  # Fall back to regular accuracy\n",
    "                    \n",
    "                f1_micro = f1_score(category_true, category_pred, average='micro')\n",
    "                \n",
    "                metrics_per_category[category] = {\n",
    "                    'accuracy': accuracy,\n",
    "                    'balanced_accuracy': balanced_acc,\n",
    "                    'f1_micro': f1_micro,\n",
    "                    'samples': len(category_true)\n",
    "                }\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating metrics for category {category}: {e}\")\n",
    "    \n",
    "    # Calculate overall metrics\n",
    "    overall_metrics = {}\n",
    "    if all_true and all_pred:\n",
    "        overall_metrics['accuracy'] = accuracy_score(all_true, all_pred)\n",
    "        overall_metrics['balanced_accuracy'] = balanced_accuracy_score(all_true, all_pred)\n",
    "        overall_metrics['f1_micro'] = f1_score(all_true, all_pred, average='micro')\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n=== Overall Metrics ===\")\n",
    "    print(f\"Accuracy: {overall_metrics.get('accuracy', 0):.4f}\")\n",
    "    print(f\"Balanced Accuracy: {overall_metrics.get('balanced_accuracy', 0):.4f}\")\n",
    "    print(f\"F1 Micro: {overall_metrics.get('f1_micro', 0):.4f}\")\n",
    "    \n",
    "    metrics_df = pd.DataFrame([\n",
    "        {\n",
    "            'Category': cat,\n",
    "            'Accuracy': metrics['accuracy'],\n",
    "            'Balanced Acc': metrics['balanced_accuracy'],\n",
    "            'F1 Micro': metrics['f1_micro'],\n",
    "            'Samples': metrics['samples']\n",
    "        }\n",
    "        for cat, metrics in metrics_per_category.items()\n",
    "    ])\n",
    "    \n",
    "    if wandb_run:\n",
    "        wandb_run.log({\"accuracy\": overall_metrics.get('accuracy', 0)})\n",
    "        wandb_run.log({\"balanced_accuracy\": overall_metrics.get('balanced_accuracy', 0)})\n",
    "        wandb_run.log({\"f1_micro\": overall_metrics.get('f1_micro', 0)})\n",
    "        wandb_run.log({\"metrics_df\": wandb.Table(dataframe=metrics_df)})\n",
    "\n",
    "true_label = {\n",
    "    \"price_or_not\": 1,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 1,\n",
    "    \"price_down\": 0,\n",
    "    \"past_price_info\": 0,\n",
    "    \"future_price_info\": 1,\n",
    "    \"past_gen_info\": 0,\n",
    "    \"future_gen_info\": 0,\n",
    "    \"asset_comparison\": 0\n",
    "}\n",
    "\n",
    "pred_label = {\n",
    "    \"price_or_not\": 1,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 0,  # Incorrect prediction\n",
    "    \"price_down\": 0,\n",
    "    \"past_price_info\": -1,    # Missing prediction\n",
    "    \"future_price_info\": 1,\n",
    "    \"past_gen_info\": 0,\n",
    "    \"future_gen_info\": 0,\n",
    "    \"asset_comparison\": 0\n",
    "}\n",
    "\n",
    "# For demonstration, create a list with multiple examples\n",
    "true_labels = [true_label, true_label, true_label]\n",
    "pred_labels = [pred_label, pred_label, pred_label]\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_multilabel_performance(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean LLM Output for Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['price_or_not', 'price_up', 'price_const_stable', 'price_down', 'past_price_info', 'future_price_info', 'past_gen_info', 'future_gen_info', 'asset_comparison'])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = {\n",
    "\"price_or_not\": 1,\n",
    "\"price_up\": 0,\n",
    "\"price_const_stable\": 1,\n",
    "\"price_down\": 0,\n",
    "\"past_price_info\": 0,\n",
    "\"future_price_info\": 1,\n",
    "\"past_gen_info\": 0,\n",
    "\"future_gen_info\": 0,\n",
    "\"asset_comparison\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def process_output(input_data):\n",
    "    \"\"\"\n",
    "    Process various input formats containing financial sentiment data and return a standardized dictionary.\n",
    "    \n",
    "    Args:\n",
    "        input_data: Dictionary, string, or other format containing sentiment analysis results\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary with all expected keys and validated values (0, 1, or -1 for errors)\n",
    "    \"\"\"\n",
    "    # Define the expected keys\n",
    "    expected_keys = [\n",
    "        \"price_or_not\", \n",
    "        \"price_up\", \n",
    "        \"price_const_stable\", \n",
    "        \"price_down\", \n",
    "        \"past_price_info\", \n",
    "        \"future_price_info\", \n",
    "        \"past_gen_info\", \n",
    "        \"future_gen_info\", \n",
    "        \"asset_comparison\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize result dictionary with all keys set to -1\n",
    "    result = {key: -1 for key in expected_keys}\n",
    "    \n",
    "    # Parse input to dictionary if it's not already\n",
    "    parsed_data = {}\n",
    "    \n",
    "    if isinstance(input_data, dict):\n",
    "        parsed_data = input_data\n",
    "    elif isinstance(input_data, str):\n",
    "        # Remove markdown code blocks if present\n",
    "        clean_input = re.sub(r'```(?:json|python)?\\s*|\\s*```', '', input_data)\n",
    "        \n",
    "        # Try to find and extract JSON-like structure from text\n",
    "        json_pattern = r'(?:\\{|\\[).*?(?:\\}|\\])'\n",
    "        json_matches = re.findall(json_pattern, clean_input, re.DOTALL)\n",
    "        \n",
    "        if json_matches:\n",
    "            # Try each potential JSON match\n",
    "            for json_str in json_matches:\n",
    "                try:\n",
    "                    candidate = json.loads(json_str)\n",
    "                    if isinstance(candidate, dict) and any(key in candidate for key in expected_keys):\n",
    "                        parsed_data = candidate\n",
    "                        break\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        # If no valid JSON was found, try direct parsing\n",
    "        if not parsed_data:\n",
    "            try:\n",
    "                parsed_data = json.loads(clean_input)\n",
    "            except json.JSONDecodeError:\n",
    "                # Try to parse Python dict syntax\n",
    "                try:\n",
    "                    # Replace single quotes with double quotes for JSON parsing\n",
    "                    clean_input = clean_input.replace(\"'\", '\"')\n",
    "                    parsed_data = json.loads(clean_input)\n",
    "                except json.JSONDecodeError:\n",
    "                    # Try to extract key-value pairs using regex\n",
    "                    pairs = re.findall(r'\"?(\\w+)\"?\\s*:\\s*(-?\\d+)', clean_input)\n",
    "                    parsed_data = {key: int(value) for key, value in pairs}\n",
    "    \n",
    "    # Update result with valid values from parsed data\n",
    "    for key in expected_keys:\n",
    "        if key in parsed_data:\n",
    "            # Ensure value is 0 or 1, otherwise set to -1\n",
    "            if parsed_data[key] in [0, 1]:\n",
    "                result[key] = parsed_data[key]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'price_or_not': 1, 'price_up': 0, 'price_const_stable': 1, 'price_down': 0, 'past_price_info': 0, 'future_price_info': 1, 'past_gen_info': -1, 'future_gen_info': -1, 'asset_comparison': -1}\n",
      "{'price_or_not': 1, 'price_up': 0, 'price_const_stable': 1, 'price_down': -1, 'past_price_info': -1, 'future_price_info': -1, 'past_gen_info': -1, 'future_gen_info': -1, 'asset_comparison': -1}\n",
      "{'price_or_not': 1, 'price_up': 0, 'price_const_stable': 1, 'price_down': 0, 'past_price_info': -1, 'future_price_info': -1, 'past_gen_info': -1, 'future_gen_info': -1, 'asset_comparison': -1}\n",
      "{'price_or_not': -1, 'price_up': -1, 'price_const_stable': -1, 'price_down': -1, 'past_price_info': -1, 'future_price_info': -1, 'past_gen_info': -1, 'future_gen_info': -1, 'asset_comparison': -1}\n",
      "{'price_or_not': 1, 'price_up': 0, 'price_const_stable': 1, 'price_down': 0, 'past_price_info': 0, 'future_price_info': 1, 'past_gen_info': -1, 'future_gen_info': -1, 'asset_comparison': -1}\n",
      "{'price_or_not': 1, 'price_up': 0, 'price_const_stable': 1, 'price_down': 0, 'past_price_info': 0, 'future_price_info': 1, 'past_gen_info': -1, 'future_gen_info': -1, 'asset_comparison': -1}\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Dictionary input\n",
    "output1 = {\n",
    "    \"price_or_not\": 1,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 1,\n",
    "    \"price_down\": 0,\n",
    "    \"past_price_info\": 0,\n",
    "    \"future_price_info\": 1\n",
    "}\n",
    "result1 = process_output(output1)\n",
    "print(result1)  # Missing keys will have value -1\n",
    "\n",
    "# Example 2: JSON string input\n",
    "output2 = '{\"price_or_not\": 1, \"price_up\": 0, \"price_const_stable\": 1}'\n",
    "result2 = process_output(output2)\n",
    "print(result2)\n",
    "\n",
    "# Example 3: Markdown code block\n",
    "output3 = '''```json\n",
    "{\n",
    "    \"price_or_not\": 1,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 1,\n",
    "    \"price_down\": 0\n",
    "}\n",
    "```'''\n",
    "result3 = process_output(output3)\n",
    "print(result3)\n",
    "\n",
    "# Example 4: Invalid values\n",
    "output4 = {\"price_or_not\": 2, \"price_up\": \"yes\"}\n",
    "result4 = process_output(output4)\n",
    "print(result4)  # All values will be -1 as they're invalid\n",
    "\n",
    "# Example with JSON embedded in text\n",
    "mixed_text = \"\"\"\n",
    "After analyzing the financial news, here's my assessment:\n",
    "\n",
    "{\n",
    "    \"price_or_not\": 1,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 1,\n",
    "    \"price_down\": 0,\n",
    "    \"past_price_info\": 0,\n",
    "    \"future_price_info\": 1\n",
    "}\n",
    "\n",
    "I hope this information is helpful for your investment decisions.\n",
    "\"\"\"\n",
    "\n",
    "result = process_output(mixed_text)\n",
    "print(result)\n",
    "\n",
    "# Incomplete JSON example\n",
    "incomplete_json = '''\n",
    "{\n",
    "    \"price_or_not\": 1,\n",
    "    \"price_up\": 0,\n",
    "    \"price_const_stable\": 1,\n",
    "    \"price_down\": 0,\n",
    "    \"past_price_info\": 0,\n",
    "    \"future_price_info\": 1\n",
    "'''\n",
    "result = process_output(incomplete_json)\n",
    "print(result)  # Should handle incomplete JSON gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test gold dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_manager import GoldDataManager\n",
    "\n",
    "prompts, true_labels, pred_labels = GoldDataManager.load_data(\"gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model outputs on train / valid / test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from src.models.hf_utils import HF_Manager\n",
    "from src.data.data_transforms import DataTransforms\n",
    "\n",
    "model_output_dir = \"models/sentiment:50agree/llama3.2:1b/deft-pyramid-98\"\n",
    "\n",
    "dataset = load_from_disk(f\"distillation-data/sentiment:allagree/llama3.1:405b/silver-grass-20-mod\") # load the distillation dataset \n",
    "dataset = DataTransforms.split_data(dataset) # split the train dataset into train and test/valid sets\n",
    "train_dataset = dataset[\"train\"]\n",
    "valid_dataset = dataset[\"test\"]\n",
    "test_dataset = load_from_disk(f\"data/sentiment:50agree/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test inference with model models/sentiment:50agree/llama3.2:1b/deft-pyramid-98 on dataset (3100, 3). Limit: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 1/2 [00:53<00:53, 53.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: The Board of Directors has proposed the Extraordinary General Meeting to authorise the Board to decide on the issuance of a maximum of 30mn new shares in one or more share issues .\n",
      "Final Label: \n",
      "Completion by student: Neutral\n",
      "Completion by teacher: neutral\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:46<00:00, 53.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Finnish forest machinery manufacturer Ponsse 's net sales grew to EUR 51.3 mn in the first quarter of 2010 from EUR 37.5 mn in the corresponding period in 2009 .\n",
      "Final Label: \n",
      "Completion by student: positive\n",
      "Completion by teacher: positive\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "HF_Manager.predict(model_path=model_output_dir, dataset=train_dataset, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test inference with model models/sentiment:50agree/llama3.2:1b/deft-pyramid-98 on dataset (776, 3). Limit: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 1/2 [04:34<04:34, 274.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: The mill has long traditions and holds an established position in the markets .\n",
      "Final Label: \n",
      "Completion by student: neutral\n",
      "Completion by teacher: positive\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|██████████| 2/2 [06:49<00:00, 204.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: In the Baltic states the company reports net sales of EUR 11.9 mn , down from EUR 14.2 mn , and an operative EBIT of EUR -2.2 mn , down from EUR -1.7 mn .\n",
      "Final Label: \n",
      "Completion by student: neutral\n",
      "Completion by teacher: negative\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "HF_Manager.predict(model_path=model_output_dir, dataset=valid_dataset, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test inference with model models/sentiment:50agree/llama3.2:1b/deft-pyramid-98 on dataset (970, 2). Limit: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 1/2 [00:45<00:45, 45.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion before processing: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Profit before taxes was EUR 5.4 mn , up from EUR 3.6 mn a year earlier .\n",
      "Final Label:  negative\n",
      "Example 0:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Profit before taxes was EUR 5.4 mn , up from EUR 3.6 mn a year earlier .\n",
      "Final Label: \n",
      "Completion by student: negative\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:31<00:00, 45.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion before processing: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Kaupthing Bank will publish its annual results for 2007 before markets open on Thursday 31 January .\n",
      "Final Label:  neutral\n",
      "Example 1:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Kaupthing Bank will publish its annual results for 2007 before markets open on Thursday 31 January .\n",
      "Final Label: \n",
      "Completion by student: neutral\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "HF_Manager.predict(model_path=model_output_dir, dataset=test_dataset, limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify prompt to end with 'Final Label:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3876/3876 [00:00<00:00, 34116.99 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 3876/3876 [00:00<00:00, 1041055.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(f\"models/sentiment:50agree/llama3.1:405b/inference_outputs/silver-grass-20\")\n",
    "\n",
    "# Define a function to modify the 'prompt' column\n",
    "def modify_prompt(example):\n",
    "    last_index = example['prompt'].rfind('Label: ')\n",
    "    if last_index != -1:\n",
    "        example['prompt'] = example['prompt'][:last_index] + 'Final Label: ' + example['prompt'][last_index + len('Label: '):]\n",
    "    return example\n",
    "\n",
    "# Apply the transformation using map\n",
    "dataset = dataset.map(modify_prompt)\n",
    "\n",
    "# Save the modified dataset\n",
    "dataset.save_to_disk(\"models/sentiment:50agree/llama3.1:405b/inference_outputs/silver-grass-20-mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a highly qualified expert trained to annotate machine learning training data.\\n\\nYour task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\\npositive, negative, or neutral.\\n\\nBase your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \\n\\nDo not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\\n\\nExamples:\\nText: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\\nLabel: positive\\nText: The company generated net sales of 11.3 million euro this year.\\nLabel: neutral\\nText: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\\t\\nLabel: negative\\n\\nYour TEXT to analyse:\\nTEXT: Sanoma Magazines International will invite other shareholders holding approximately 15 % of the shares to sell their shares .\\nFinal Label: '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(f\"models/sentiment:50agree/llama3.1:405b/inference_outputs/silver-grass-20-mod\")\n",
    "dataset[0]['prompt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push model to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 4.94G/4.94G [04:02<00:00, 20.4MB/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/hendrik-spl/test_honest-serenity-73/commit/9af4b95dac2fafc3bc99f5991c7756c82027998f', commit_message='Upload LlamaForCausalLM', commit_description='', oid='9af4b95dac2fafc3bc99f5991c7756c82027998f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hendrik-spl/test_honest-serenity-73', endpoint='https://huggingface.co', repo_type='model', repo_id='hendrik-spl/test_honest-serenity-73'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push to Hugging Face Hub\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"models/sentiment:50agree/llama3.2:1b/checkpoints/honest-serenity-73\"\n",
    "\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "hf_model.push_to_hub(\"hendrik-spl/test_honest-serenity-73\")\n",
    "hf_tokenizer.push_to_hub(\"hendrik-spl/test_honest-serenity-73\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing token length of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarization Task #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 3648.6995835812018\n",
      "Max length: 13910\n",
      "% truncated at 256: 99.76%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PROMPT + INPUT TEXT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.prompts.summary import get_summmary_prompt\n",
    "from src.data.data_manager import SummaryManager\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = SummaryManager.load_original_data()\n",
    "\n",
    "lengths = [len(tokenizer.encode(get_summmary_prompt(example['text']))) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 256: {sum(l > 768 for l in lengths)/len(lengths):.2%}\")\n",
    "\n",
    "# plot the distibution of the lengths\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(lengths, bins=50, kde=True)\n",
    "plt.title(\"Task #3: Length Distribution of Tokenized Inputs (Prompt + Text)\")\n",
    "plt.xlabel(\"Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 3538.7138607971447\n",
      "Max length: 13800\n",
      "% truncated at 256: 99.58%\n"
     ]
    }
   ],
   "source": [
    "# ONLY INPUT TEXT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.prompts.summary import get_summmary_prompt\n",
    "from src.data.data_manager import SummaryManager\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = SummaryManager.load_original_data()\n",
    "\n",
    "lengths = [len(tokenizer.encode(example['text'])) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 256: {sum(l > 768 for l in lengths)/len(lengths):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 75.08387864366449\n",
      "Max length: 388\n",
      "% truncated at 384: 0.06%\n"
     ]
    }
   ],
   "source": [
    "# ONLY TARGET OUTPUTS (Summaries)\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.prompts.summary import get_summmary_prompt\n",
    "from src.data.data_manager import SummaryManager\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = SummaryManager.load_original_data()\n",
    "\n",
    "lengths = [len(tokenizer.encode(example['summary'])) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 384: {sum(l > 384 for l in lengths)/len(lengths):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gold Task #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 709.9885208552402\n",
      "Max length: 735\n",
      "% truncated at 256: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# INCLUDING PROMPT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.prompts.gold import get_gold_classification_prompt\n",
    "from src.data.data_manager import GoldDataManager\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = GoldDataManager.load_original_data()\n",
    "\n",
    "lengths = [len(tokenizer.encode(get_gold_classification_prompt(example['News']))) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 768: {sum(l > 768 for l in lengths)/len(lengths):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY OUTPUT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "example = '''{\n",
    "\"price_or_not\": 0,\n",
    "\"price_up\": 0,\n",
    "\"price_const_stable\": 1,\n",
    "\"price_down\": 1,\n",
    "\"past_price_info\": 0,\n",
    "\"future_price_info\": 0,\n",
    "\"past_gen_info\": 0,\n",
    "\"future_gen_info\": 0,'''\n",
    "\n",
    "lengths = len(tokenizer.encode(example))\n",
    "print(f\"Length: {lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 14.126883981773572\n",
      "Max length: 39\n",
      "% truncated at 256: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# WITHOUT PROMPT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.prompts.gold import get_gold_classification_prompt\n",
    "from src.data.data_manager import GoldDataManager\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = GoldDataManager.load_original_data()\n",
    "\n",
    "lengths = [len(tokenizer.encode(example['News'])) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 256: {sum(l > 256 for l in lengths)/len(lengths):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Task #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 30.292818819645067\n",
      "Max length: 135\n",
      "% truncated at 256: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# WITHOUT PROMPT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = load_dataset(path=\"takala/financial_phrasebank\", name=\"sentences_50agree\", trust_remote_code=True)\n",
    "\n",
    "lengths = [len(tokenizer.encode(example['sentence'])) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 256: {sum(l > 256 for l in lengths)/len(lengths):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the outputs of different models across HF and ollama on sample prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer meta-llama/Llama-3.2-1B-Instruct does not have a pad token. Setting pad token to eos token.\n",
      "Running model meta-llama/Llama-3.2-1B-Instruct with prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: After a long up and down, the stock market is finally on the rise, says the analyst.\n",
      "Label: \n",
      "Implemented stopping criteria: [<src.models.hf_stopping.KeywordStoppingCriteria object at 0x31fe942d0>]\n",
      "Response 1:\n",
      "Reponse:  neutral\n",
      "TEXT:\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Implemented stopping criteria: [<src.models.hf_stopping.KeywordStoppingCriteria object at 0x31eafce90>]\n",
      "Response 2:\n",
      "Reponse:  neutral\n",
      "TEXT:\n",
      "Cleaned response: neutral\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untrained llama straight from hf but with KeyWordStoppingCriteria implemented in query_hf_model\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    print(f\"Tokenizer {tokenizer.name_or_path} does not have a pad token. Setting pad token to eos token.\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Make sure we're setting a single integer ID\n",
    "    if isinstance(model.config.eos_token_id, list):\n",
    "        # If eos_token_id is a list, use the first element\n",
    "        model.config.pad_token_id = model.config.eos_token_id[0]\n",
    "    else:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "model_config = (model, tokenizer)\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "print(f\"Running model {model_path} with prompt: {prompt}\")\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=2,\n",
    "    use_ollama=False,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "Reponse: neutral\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 2:\n",
      "Reponse: neutral\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 3:\n",
      "Reponse: negative\n",
      "Cleaned response: negative\n",
      "------------\n",
      "Response 4:\n",
      "Reponse: negative\n",
      "Cleaned response: negative\n",
      "------------\n",
      "Response 5:\n",
      "Reponse: negative\n",
      "Cleaned response: negative\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ollama llama3.2:1b\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "model_config = \"llama3.2:1b\"\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=5,\n",
    "    use_ollama=True,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer meta-llama/Llama-3.2-1B-Instruct does not have a pad token. Setting pad token to eos token.\n",
      "Running model meta-llama/Llama-3.2-1B-Instruct with prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: After a long up and down, the stock market is finally on the rise, says the analyst.\n",
      "Label: \n",
      "Response 1:\n",
      "Reponse:  neutral\n",
      "TEXT: The company has been struggling to find a new investor, despite having a strong financial\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 2:\n",
      "Reponse:  positive\n",
      "TEXT: The company's financials are looking good, with a 20% increase in\n",
      "Cleaned response: positive\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untrained llama straight from hf\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    print(f\"Tokenizer {tokenizer.name_or_path} does not have a pad token. Setting pad token to eos token.\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Make sure we're setting a single integer ID\n",
    "    if isinstance(model.config.eos_token_id, list):\n",
    "        # If eos_token_id is a list, use the first element\n",
    "        model.config.pad_token_id = model.config.eos_token_id[0]\n",
    "    else:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "model_config = (model, tokenizer)\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "print(f\"Running model {model_path} with prompt: {prompt}\")\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=2,\n",
    "    use_ollama=False,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "Reponse:  positive\n",
      "TEXT: The company's financials are looking better, with a 10% increase in\n",
      "Cleaned response: positive\n",
      "------------\n",
      "Response 2:\n",
      "Reponse:  positive\n",
      "TEXT: The company has been struggling to meet its quarterly targets, and its stock price has\n",
      "Cleaned response: positive\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Untrained hf base model\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"models/sentiment:50agree/llama3.2:1b/checkpoints/dazzling-forest-66\" # base model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model_config = (model, tokenizer)\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=2,\n",
    "    use_ollama=False,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:  positive\n",
      "TEXT: The company's financials are looking better than expected, but the market is still\n",
      "Reponse:  positive\n",
      "TEXT: The company's financials are looking better than expected, but the market is still\n",
      "Cleaned response: positive\n",
      "------------\n",
      "Response 2:  neutral\n",
      "TEXT: The company has been struggling to turn a profit for several years, and the recent\n",
      "Reponse:  neutral\n",
      "TEXT: The company has been struggling to turn a profit for several years, and the recent\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 3:  positive\n",
      "TEXT: The company has been struggling to stay afloat, despite efforts to improve its financial\n",
      "Reponse:  positive\n",
      "TEXT: The company has been struggling to stay afloat, despite efforts to improve its financial\n",
      "Cleaned response: positive\n",
      "------------\n",
      "Response 4:  neutral\n",
      "TEXT: The company has been struggling to make ends meet, despite its efforts to increase production\n",
      "Reponse:  neutral\n",
      "TEXT: The company has been struggling to make ends meet, despite its efforts to increase production\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 5:  neutral\n",
      "TEXT: The company has been struggling to maintain its market share in the highly competitive tech industry\n",
      "Reponse:  neutral\n",
      "TEXT: The company has been struggling to maintain its market share in the highly competitive tech industry\n",
      "Cleaned response: neutral\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finetuned hf model\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"models/sentiment:50agree/llama3.2:1b/checkpoints/smart-cosmos-63\" # finetuned model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model_config = (model, tokenizer)\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=2,\n",
    "    use_ollama=False,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing proper HF inference calls and understanding different approaches to eos and pad token config stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I've\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def query_hf_model(model_path, prompt):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load the model and tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Store the input length to know where the generated text starts\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "\n",
    "    # Generate a response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 max_new_tokens=2\n",
    "                                 )\n",
    "\n",
    "    # Decode ONLY the generated tokens (exclude the input prompt tokens)\n",
    "    response = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "    \n",
    "    return response\n",
    "\n",
    "query_hf_model(\"models/sentiment:50agree/llama3.2:1b/checkpoints/smart-cosmos-63\", \"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current generation config: {'bos_token_id': 128000, 'do_sample': True, 'eos_token_id': [128001, 128008, 128009], 'temperature': 0.6, 'top_p': 0.9, 'transformers_version': '4.49.0'}\n",
      "Found list in eos_token_id: [128001, 128008, 128009]\n",
      "Fixed generation config saved to: models/sentiment:50agree/llama3.2:1b/checkpoints/sparkling-waterfall-43/generation_config.json.fixed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Check if a generation_config.json exists and examine it\n",
    "gen_config_path = os.path.join(model_path, \"generation_config.json\")\n",
    "if os.path.exists(gen_config_path):\n",
    "    with open(gen_config_path, 'r') as f:\n",
    "        gen_config = json.load(f)\n",
    "        print(\"Current generation config:\", gen_config)\n",
    "        \n",
    "        # Look for list parameters that should be integers\n",
    "        for key, value in gen_config.items():\n",
    "            if isinstance(value, list) and key in [\"pad_token_id\", \"eos_token_id\", \"bos_token_id\"]:\n",
    "                print(f\"Found list in {key}: {value}\")\n",
    "                # Fix by converting to integer if needed\n",
    "                if value:\n",
    "                    gen_config[key] = value[0]\n",
    "                else:\n",
    "                    gen_config[key] = None\n",
    "        \n",
    "        # Save the fixed config\n",
    "        with open(gen_config_path + \".fixed\", 'w') as f:\n",
    "            json.dump(gen_config, f, indent=2)\n",
    "            \n",
    "        print(\"Fixed generation config saved to:\", gen_config_path + \".fixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SentimentDataManager class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory models/sentiment:50agree/smollm2:135m/inference_outputs/test123.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 140.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_manager import SentimentDataManager\n",
    "\n",
    "SentimentDataManager.save_model_outputs(\n",
    "    [\"hello\"],\n",
    "    [\"positive\"],\n",
    "    [\"neutral\"],\n",
    "    \"sentiment:50agree\",\n",
    "    \"smollm2:135m\",\n",
    "    \"test123\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure\n",
      "Dataset({\n",
      "    features: ['prompt', 'true_label', 'completion'],\n",
      "    num_rows: 10\n",
      "})\n",
      "First row\n",
      "{'prompt': 'You are a highly qualified expert trained to annotate machine learning training data.\\n\\nYour task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\\npositive, negative, or neutral.\\n\\nBase your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \\n\\nDo not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\\n\\nExamples:\\nText: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\\nLabel: positive\\nText: The company generated net sales of 11.3 million euro this year.\\nLabel: neutral\\nText: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\\t\\nLabel: negative\\n\\nYour TEXT to analyse:\\nTEXT: Sanoma Magazines International will invite other shareholders holding approximately 15 % of the shares to sell their shares .\\nLabel: ', 'true_label': 1, 'completion': 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"models/sentiment:50agree/smollm2:135m/inference_outputs/elated-grass-15\")\n",
    "\n",
    "print(\"Dataset structure\")\n",
    "print(dataset)\n",
    "\n",
    "print(\"First row\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset sentences_50agree with 4846 training samples.\n"
     ]
    }
   ],
   "source": [
    "from src.data.process_datasets import get_processed_hf_dataset\n",
    "\n",
    "sentences, true_labels = get_processed_hf_dataset(dataset=\"sentiment\", split_mode=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with PEFT LoRA stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 851,968 || all params: 1,236,666,368 || trainable%: 0.0689\n"
     ]
    }
   ],
   "source": [
    "from src.models.hf_utils import load_model_from_hf\n",
    "\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model, tokenizer = load_model_from_hf(\"llama3.2:1b\")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 45.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 25 Mar 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Which is bigger, the moon or the sun?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The sun.<|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "\n",
    "chat1 = [\n",
    "    {\"role\": \"user\", \"content\": \"Which is bigger, the moon or the sun?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The sun.\"}\n",
    "]\n",
    "chat2 = [\n",
    "    {\"role\": \"user\", \"content\": \"Which is bigger, a virus or a bacterium?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"A bacterium.\"}\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_dict({\"chat\": [chat1, chat2]})\n",
    "dataset = dataset.map(lambda x: {\"formatted_chat\": tokenizer.apply_chat_template(x[\"chat\"], tokenize=False, add_generation_prompt=False)})\n",
    "print(dataset['formatted_chat'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
