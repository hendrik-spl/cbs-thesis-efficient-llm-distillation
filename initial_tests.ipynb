{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test gold dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_manager import GoldDataManager\n",
    "\n",
    "prompts, true_labels, pred_labels = GoldDataManager.load_data(\"gold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model outputs on train / valid / test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from src.models.hf_utils import HF_Manager\n",
    "from src.data.data_transforms import DataTransforms\n",
    "\n",
    "model_output_dir = \"models/sentiment:50agree/llama3.2:1b/deft-pyramid-98\"\n",
    "\n",
    "dataset = load_from_disk(f\"distillation-data/sentiment:allagree/llama3.1:405b/silver-grass-20-mod\") # load the distillation dataset \n",
    "dataset = DataTransforms.split_data(dataset) # split the train dataset into train and test/valid sets\n",
    "train_dataset = dataset[\"train\"]\n",
    "valid_dataset = dataset[\"test\"]\n",
    "test_dataset = load_from_disk(f\"data/sentiment:50agree/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test inference with model models/sentiment:50agree/llama3.2:1b/deft-pyramid-98 on dataset (3100, 3). Limit: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 1/2 [00:53<00:53, 53.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: The Board of Directors has proposed the Extraordinary General Meeting to authorise the Board to decide on the issuance of a maximum of 30mn new shares in one or more share issues .\n",
      "Final Label: \n",
      "Completion by student: Neutral\n",
      "Completion by teacher: neutral\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:46<00:00, 53.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Finnish forest machinery manufacturer Ponsse 's net sales grew to EUR 51.3 mn in the first quarter of 2010 from EUR 37.5 mn in the corresponding period in 2009 .\n",
      "Final Label: \n",
      "Completion by student: positive\n",
      "Completion by teacher: positive\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "HF_Manager.predict(model_path=model_output_dir, dataset=train_dataset, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test inference with model models/sentiment:50agree/llama3.2:1b/deft-pyramid-98 on dataset (776, 3). Limit: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 1/2 [04:34<04:34, 274.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: The mill has long traditions and holds an established position in the markets .\n",
      "Final Label: \n",
      "Completion by student: neutral\n",
      "Completion by teacher: positive\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|██████████| 2/2 [06:49<00:00, 204.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: In the Baltic states the company reports net sales of EUR 11.9 mn , down from EUR 14.2 mn , and an operative EBIT of EUR -2.2 mn , down from EUR -1.7 mn .\n",
      "Final Label: \n",
      "Completion by student: neutral\n",
      "Completion by teacher: negative\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "HF_Manager.predict(model_path=model_output_dir, dataset=valid_dataset, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test inference with model models/sentiment:50agree/llama3.2:1b/deft-pyramid-98 on dataset (970, 2). Limit: 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 1/2 [00:45<00:45, 45.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion before processing: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Profit before taxes was EUR 5.4 mn , up from EUR 3.6 mn a year earlier .\n",
      "Final Label:  negative\n",
      "Example 0:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Profit before taxes was EUR 5.4 mn , up from EUR 3.6 mn a year earlier .\n",
      "Final Label: \n",
      "Completion by student: negative\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:31<00:00, 45.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion before processing: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Kaupthing Bank will publish its annual results for 2007 before markets open on Thursday 31 January .\n",
      "Final Label:  neutral\n",
      "Example 1:\n",
      "Prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: Kaupthing Bank will publish its annual results for 2007 before markets open on Thursday 31 January .\n",
      "Final Label: \n",
      "Completion by student: neutral\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "HF_Manager.predict(model_path=model_output_dir, dataset=test_dataset, limit=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify prompt to end with 'Final Label:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3876/3876 [00:00<00:00, 34116.99 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 3876/3876 [00:00<00:00, 1041055.48 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(f\"models/sentiment:50agree/llama3.1:405b/inference_outputs/silver-grass-20\")\n",
    "\n",
    "# Define a function to modify the 'prompt' column\n",
    "def modify_prompt(example):\n",
    "    last_index = example['prompt'].rfind('Label: ')\n",
    "    if last_index != -1:\n",
    "        example['prompt'] = example['prompt'][:last_index] + 'Final Label: ' + example['prompt'][last_index + len('Label: '):]\n",
    "    return example\n",
    "\n",
    "# Apply the transformation using map\n",
    "dataset = dataset.map(modify_prompt)\n",
    "\n",
    "# Save the modified dataset\n",
    "dataset.save_to_disk(\"models/sentiment:50agree/llama3.1:405b/inference_outputs/silver-grass-20-mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a highly qualified expert trained to annotate machine learning training data.\\n\\nYour task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\\npositive, negative, or neutral.\\n\\nBase your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \\n\\nDo not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\\n\\nExamples:\\nText: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\\nLabel: positive\\nText: The company generated net sales of 11.3 million euro this year.\\nLabel: neutral\\nText: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\\t\\nLabel: negative\\n\\nYour TEXT to analyse:\\nTEXT: Sanoma Magazines International will invite other shareholders holding approximately 15 % of the shares to sell their shares .\\nFinal Label: '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(f\"models/sentiment:50agree/llama3.1:405b/inference_outputs/silver-grass-20-mod\")\n",
    "dataset[0]['prompt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push model to hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 4.94G/4.94G [04:02<00:00, 20.4MB/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/hendrik-spl/test_honest-serenity-73/commit/9af4b95dac2fafc3bc99f5991c7756c82027998f', commit_message='Upload LlamaForCausalLM', commit_description='', oid='9af4b95dac2fafc3bc99f5991c7756c82027998f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/hendrik-spl/test_honest-serenity-73', endpoint='https://huggingface.co', repo_type='model', repo_id='hendrik-spl/test_honest-serenity-73'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push to Hugging Face Hub\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"models/sentiment:50agree/llama3.2:1b/checkpoints/honest-serenity-73\"\n",
    "\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "hf_model.push_to_hub(\"hendrik-spl/test_honest-serenity-73\")\n",
    "hf_tokenizer.push_to_hub(\"hendrik-spl/test_honest-serenity-73\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing token length of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 709.9885208552402\n",
      "Max length: 735\n",
      "% truncated at 256: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# INCLUDING PROMPT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.prompts.gold import get_gold_classification_prompt\n",
    "from src.data.data_manager import GoldDataManager\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = GoldDataManager.load_original_data()\n",
    "\n",
    "lengths = [len(tokenizer.encode(get_gold_classification_prompt(example['News']))) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 256: {sum(l > 768 for l in lengths)/len(lengths):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 14.126883981773572\n",
      "Max length: 39\n",
      "% truncated at 256: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# WITHOUT PROMPT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from src.prompts.gold import get_gold_classification_prompt\n",
    "from src.data.data_manager import GoldDataManager\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = GoldDataManager.load_original_data()\n",
    "\n",
    "lengths = [len(tokenizer.encode(example['News'])) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 256: {sum(l > 256 for l in lengths)/len(lengths):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length: 30.292818819645067\n",
      "Max length: 135\n",
      "% truncated at 256: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# WITHOUT PROMPT\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "dataset = load_dataset(path=\"takala/financial_phrasebank\", name=\"sentences_50agree\", trust_remote_code=True)\n",
    "\n",
    "lengths = [len(tokenizer.encode(example['sentence'])) for example in dataset['train']]\n",
    "print(f\"Average length: {sum(lengths)/len(lengths)}\")\n",
    "print(f\"Max length: {max(lengths)}\")\n",
    "print(f\"% truncated at 256: {sum(l > 256 for l in lengths)/len(lengths):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the outputs of different models across HF and ollama on sample prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer meta-llama/Llama-3.2-1B-Instruct does not have a pad token. Setting pad token to eos token.\n",
      "Running model meta-llama/Llama-3.2-1B-Instruct with prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: After a long up and down, the stock market is finally on the rise, says the analyst.\n",
      "Label: \n",
      "Implemented stopping criteria: [<src.models.hf_stopping.KeywordStoppingCriteria object at 0x31fe942d0>]\n",
      "Response 1:\n",
      "Reponse:  neutral\n",
      "TEXT:\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Implemented stopping criteria: [<src.models.hf_stopping.KeywordStoppingCriteria object at 0x31eafce90>]\n",
      "Response 2:\n",
      "Reponse:  neutral\n",
      "TEXT:\n",
      "Cleaned response: neutral\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untrained llama straight from hf but with KeyWordStoppingCriteria implemented in query_hf_model\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    print(f\"Tokenizer {tokenizer.name_or_path} does not have a pad token. Setting pad token to eos token.\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Make sure we're setting a single integer ID\n",
    "    if isinstance(model.config.eos_token_id, list):\n",
    "        # If eos_token_id is a list, use the first element\n",
    "        model.config.pad_token_id = model.config.eos_token_id[0]\n",
    "    else:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "model_config = (model, tokenizer)\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "print(f\"Running model {model_path} with prompt: {prompt}\")\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=2,\n",
    "    use_ollama=False,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "Reponse: neutral\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 2:\n",
      "Reponse: neutral\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 3:\n",
      "Reponse: negative\n",
      "Cleaned response: negative\n",
      "------------\n",
      "Response 4:\n",
      "Reponse: negative\n",
      "Cleaned response: negative\n",
      "------------\n",
      "Response 5:\n",
      "Reponse: negative\n",
      "Cleaned response: negative\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ollama llama3.2:1b\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "model_config = \"llama3.2:1b\"\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=5,\n",
    "    use_ollama=True,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer meta-llama/Llama-3.2-1B-Instruct does not have a pad token. Setting pad token to eos token.\n",
      "Running model meta-llama/Llama-3.2-1B-Instruct with prompt: You are a highly qualified expert trained to annotate machine learning training data.\n",
      "\n",
      "Your task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\n",
      "positive, negative, or neutral.\n",
      "\n",
      "Base your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \n",
      "\n",
      "Do not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\n",
      "\n",
      "Examples:\n",
      "Text: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\n",
      "Label: positive\n",
      "Text: The company generated net sales of 11.3 million euro this year.\n",
      "Label: neutral\n",
      "Text: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\t\n",
      "Label: negative\n",
      "\n",
      "Your TEXT to analyse:\n",
      "TEXT: After a long up and down, the stock market is finally on the rise, says the analyst.\n",
      "Label: \n",
      "Response 1:\n",
      "Reponse:  neutral\n",
      "TEXT: The company has been struggling to find a new investor, despite having a strong financial\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 2:\n",
      "Reponse:  positive\n",
      "TEXT: The company's financials are looking good, with a 20% increase in\n",
      "Cleaned response: positive\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Untrained llama straight from hf\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if tokenizer.pad_token is None:\n",
    "    print(f\"Tokenizer {tokenizer.name_or_path} does not have a pad token. Setting pad token to eos token.\")\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # Make sure we're setting a single integer ID\n",
    "    if isinstance(model.config.eos_token_id, list):\n",
    "        # If eos_token_id is a list, use the first element\n",
    "        model.config.pad_token_id = model.config.eos_token_id[0]\n",
    "    else:\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "model_config = (model, tokenizer)\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "print(f\"Running model {model_path} with prompt: {prompt}\")\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=2,\n",
    "    use_ollama=False,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:\n",
      "Reponse:  positive\n",
      "TEXT: The company's financials are looking better, with a 10% increase in\n",
      "Cleaned response: positive\n",
      "------------\n",
      "Response 2:\n",
      "Reponse:  positive\n",
      "TEXT: The company has been struggling to meet its quarterly targets, and its stock price has\n",
      "Cleaned response: positive\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Untrained hf base model\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"models/sentiment:50agree/llama3.2:1b/checkpoints/dazzling-forest-66\" # base model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model_config = (model, tokenizer)\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=2,\n",
    "    use_ollama=False,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response 1:  positive\n",
      "TEXT: The company's financials are looking better than expected, but the market is still\n",
      "Reponse:  positive\n",
      "TEXT: The company's financials are looking better than expected, but the market is still\n",
      "Cleaned response: positive\n",
      "------------\n",
      "Response 2:  neutral\n",
      "TEXT: The company has been struggling to turn a profit for several years, and the recent\n",
      "Reponse:  neutral\n",
      "TEXT: The company has been struggling to turn a profit for several years, and the recent\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 3:  positive\n",
      "TEXT: The company has been struggling to stay afloat, despite efforts to improve its financial\n",
      "Reponse:  positive\n",
      "TEXT: The company has been struggling to stay afloat, despite efforts to improve its financial\n",
      "Cleaned response: positive\n",
      "------------\n",
      "Response 4:  neutral\n",
      "TEXT: The company has been struggling to make ends meet, despite its efforts to increase production\n",
      "Reponse:  neutral\n",
      "TEXT: The company has been struggling to make ends meet, despite its efforts to increase production\n",
      "Cleaned response: neutral\n",
      "------------\n",
      "Response 5:  neutral\n",
      "TEXT: The company has been struggling to maintain its market share in the highly competitive tech industry\n",
      "Reponse:  neutral\n",
      "TEXT: The company has been struggling to maintain its market share in the highly competitive tech industry\n",
      "Cleaned response: neutral\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finetuned hf model\n",
    "\n",
    "from src.models.model_utils import query_with_sc\n",
    "from src.prompts.sentiment import get_sentiment_prompt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_path = \"models/sentiment:50agree/llama3.2:1b/checkpoints/smart-cosmos-63\" # finetuned model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model_config = (model, tokenizer)\n",
    "\n",
    "prompt = get_sentiment_prompt(\"After a long up and down, the stock market is finally on the rise, says the analyst.\")\n",
    "\n",
    "response = query_with_sc(\n",
    "    model=model_config,\n",
    "    prompt=prompt,\n",
    "    shots=2,\n",
    "    use_ollama=False,\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing proper HF inference calls and understanding different approaches to eos and pad token config stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" I've\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "def query_hf_model(model_path, prompt):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load the model and tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_path).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Store the input length to know where the generated text starts\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "\n",
    "    # Generate a response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs,\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 max_new_tokens=2\n",
    "                                 )\n",
    "\n",
    "    # Decode ONLY the generated tokens (exclude the input prompt tokens)\n",
    "    response = tokenizer.decode(outputs[0][input_length:], skip_special_tokens=True)\n",
    "    \n",
    "    return response\n",
    "\n",
    "query_hf_model(\"models/sentiment:50agree/llama3.2:1b/checkpoints/smart-cosmos-63\", \"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current generation config: {'bos_token_id': 128000, 'do_sample': True, 'eos_token_id': [128001, 128008, 128009], 'temperature': 0.6, 'top_p': 0.9, 'transformers_version': '4.49.0'}\n",
      "Found list in eos_token_id: [128001, 128008, 128009]\n",
      "Fixed generation config saved to: models/sentiment:50agree/llama3.2:1b/checkpoints/sparkling-waterfall-43/generation_config.json.fixed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Check if a generation_config.json exists and examine it\n",
    "gen_config_path = os.path.join(model_path, \"generation_config.json\")\n",
    "if os.path.exists(gen_config_path):\n",
    "    with open(gen_config_path, 'r') as f:\n",
    "        gen_config = json.load(f)\n",
    "        print(\"Current generation config:\", gen_config)\n",
    "        \n",
    "        # Look for list parameters that should be integers\n",
    "        for key, value in gen_config.items():\n",
    "            if isinstance(value, list) and key in [\"pad_token_id\", \"eos_token_id\", \"bos_token_id\"]:\n",
    "                print(f\"Found list in {key}: {value}\")\n",
    "                # Fix by converting to integer if needed\n",
    "                if value:\n",
    "                    gen_config[key] = value[0]\n",
    "                else:\n",
    "                    gen_config[key] = None\n",
    "        \n",
    "        # Save the fixed config\n",
    "        with open(gen_config_path + \".fixed\", 'w') as f:\n",
    "            json.dump(gen_config, f, indent=2)\n",
    "            \n",
    "        print(\"Fixed generation config saved to:\", gen_config_path + \".fixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test SentimentDataManager class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendriksippel/Documents/Repositories/cbs-thesis-efficient-llm-distillation/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created directory models/sentiment:50agree/smollm2:135m/inference_outputs/test123.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 140.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from src.data.data_manager import SentimentDataManager\n",
    "\n",
    "SentimentDataManager.save_model_outputs(\n",
    "    [\"hello\"],\n",
    "    [\"positive\"],\n",
    "    [\"neutral\"],\n",
    "    \"sentiment:50agree\",\n",
    "    \"smollm2:135m\",\n",
    "    \"test123\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure\n",
      "Dataset({\n",
      "    features: ['prompt', 'true_label', 'completion'],\n",
      "    num_rows: 10\n",
      "})\n",
      "First row\n",
      "{'prompt': 'You are a highly qualified expert trained to annotate machine learning training data.\\n\\nYour task is to analyze the sentiment in the TEXT below from an investor perspective and label it with only one the three labels:\\npositive, negative, or neutral.\\n\\nBase your label decision only on the TEXT and do not speculate e.g. based on prior knowledge about a company. \\n\\nDo not provide any explanations and only respond with one of the labels as one word: negative, positive, or neutral\\n\\nExamples:\\nText: Operating profit increased, from EUR 7m to 9m compared to the previous reporting period.\\nLabel: positive\\nText: The company generated net sales of 11.3 million euro this year.\\nLabel: neutral\\nText: Profit before taxes decreased to EUR 14m, compared to EUR 19m in the previous period.\\t\\nLabel: negative\\n\\nYour TEXT to analyse:\\nTEXT: Sanoma Magazines International will invite other shareholders holding approximately 15 % of the shares to sell their shares .\\nLabel: ', 'true_label': 1, 'completion': 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(\"models/sentiment:50agree/smollm2:135m/inference_outputs/elated-grass-15\")\n",
    "\n",
    "print(\"Dataset structure\")\n",
    "print(dataset)\n",
    "\n",
    "print(\"First row\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset sentences_50agree with 4846 training samples.\n"
     ]
    }
   ],
   "source": [
    "from src.data.process_datasets import get_processed_hf_dataset\n",
    "\n",
    "sentences, true_labels = get_processed_hf_dataset(dataset=\"sentiment\", split_mode=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with PEFT LoRA stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 851,968 || all params: 1,236,666,368 || trainable%: 0.0689\n"
     ]
    }
   ],
   "source": [
    "from src.models.hf_utils import load_model_from_hf\n",
    "\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "\n",
    "model, tokenizer = load_model_from_hf(\"llama3.2:1b\")\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 45.87 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 25 Mar 2025\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Which is bigger, the moon or the sun?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The sun.<|eot_id|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B-Instruct\")\n",
    "\n",
    "chat1 = [\n",
    "    {\"role\": \"user\", \"content\": \"Which is bigger, the moon or the sun?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"The sun.\"}\n",
    "]\n",
    "chat2 = [\n",
    "    {\"role\": \"user\", \"content\": \"Which is bigger, a virus or a bacterium?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"A bacterium.\"}\n",
    "]\n",
    "\n",
    "dataset = Dataset.from_dict({\"chat\": [chat1, chat2]})\n",
    "dataset = dataset.map(lambda x: {\"formatted_chat\": tokenizer.apply_chat_template(x[\"chat\"], tokenize=False, add_generation_prompt=False)})\n",
    "print(dataset['formatted_chat'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
